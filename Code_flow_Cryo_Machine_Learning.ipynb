{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Flow CryoSat-2 Machine Learning\n",
    "## 19th Sept 2018\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# New ipynb for us to do ML\n",
    "# what modules do we need?\n",
    "\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Read the csv file of training data:\n",
    "training_data = pandas.read_csv('C:\\Users\\ste_j\\Desktop\\UCL-Test\\Github\\Cryo-Lead-ML\\Individual_RF.csv')\n",
    "\n",
    "train_x = data[['STD','Skew','kurtosis','PP','Sigma']]\n",
    "train_y = data [['Class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in the hdf files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in the ESA schemes for CryoSat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data editting and formatiing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run the machie learning\n",
    "# what scheme to use.... tensor flow maybe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot something\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop, adam\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29160,)\n",
      "[['2.12' '6.81' '62.08' '0.404739407' '35.35' 'lead']\n",
      " ['0.5' '15.4' '237.15' '0.43473502' '38.18' 'lead']\n",
      " ['0.51' '15.34' '236.08' '0.343635134' '33.98' 'lead']\n",
      " ...\n",
      " ['54.33' '0.25' '-0.96' '0.035372642' '16.45' 'ocean']\n",
      " ['53.94' '0.21' '-0.97' '0.033691247' '17.75' 'ocean']\n",
      " ['50.17' '0.33' '-1.23' '0.038031541' '17.02' 'ocean']]\n"
     ]
    }
   ],
   "source": [
    "#loading in the CSV file:\n",
    "#dataset = np.loadtxt(\"Individual_RF.csv\", delimiter = \",\")\n",
    "arr = []\n",
    "with open('Individual_RF.csv', 'r') as csvfile:\n",
    "    readCSV = csv.DictReader(csvfile)\n",
    "    #establishing the headers as the first line of the file:\n",
    "    headers = readCSV.fieldnames\n",
    "    for line in readCSV:\n",
    "\n",
    "        #adding to the arrays:\n",
    "        #adding the line:\n",
    "        for i in range(len(headers)):\n",
    "            \n",
    "            arr.append(line[headers[i]])\n",
    "#       .append(line[headers[0]]) # you could also write: nlc.append(line[headers[0]])\n",
    "#         Station.append(line[headers[1]])   \n",
    "#         Borough.append(line[headers[2]])\n",
    "print(np.shape(arr))\n",
    "csv_arr = np.reshape(arr, (int(round(len(arr)/6)), 6))\n",
    "print(csv_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # dataset = np.loadtxt(\"Individual_RF.csv\", delimiter = \",\", skiprows = 1)\n",
    "# with open('Individual_RF.csv') as f:\n",
    "#     lines = (line for line in f if not line.startswith('#'))\n",
    "#     FH = np.loadtxt(lines, delimiter=',', skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14580\n",
      "(4860, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_frame = pd.read_csv('Individual_RF.csv')\n",
    "all_classes = data_frame['Class'].values\n",
    "all_features = data_frame.drop('Class', axis=1).values\n",
    "\n",
    "one_hot_flat = []\n",
    "for label in all_classes:\n",
    "    if label =='lead':\n",
    "        one_hot_flat.extend([1,0,0])\n",
    "    if label =='ice':\n",
    "        one_hot_flat.extend([0,1,0])\n",
    "    if label=='ocean':\n",
    "        one_hot_flat.extend([0,0,1])\n",
    "print(np.shape(one_hot_flat)[0])\n",
    "one_hot_labels = np.reshape(one_hot_flat, (int(round(np.shape(one_hot_flat)[0]/3)), 3)) \n",
    "print(np.shape(one_hot_reshaped))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    #adding 400 nodes to the shallow layer:\n",
    "    model.add(Dense(400, input_dim=int(5), kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    # Another hidden layer of 16 units\n",
    "    #model.add(Dense(16, kernel_initializer='normal', activation='relu'))\n",
    "    #output layer\n",
    "    model.add(Dense(3, kernel_initializer='normal', activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.889094650156704"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wrap our Keras model in an estimator compatible with scikit_learn\n",
    "estimator = KerasClassifier(build_fn=create_model, epochs=30, verbose=0)\n",
    "# Now we can use scikit_learn's cross_val_score to evaluate this model identically to the others\n",
    "cv_scores = cross_val_score(estimator, all_features, one_hot_labels, cv=10) # cv = train test split (k-1: 1)\n",
    "cv_scores.mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "conda-env-Anaconda2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
   "version": "3.5.2"

  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
